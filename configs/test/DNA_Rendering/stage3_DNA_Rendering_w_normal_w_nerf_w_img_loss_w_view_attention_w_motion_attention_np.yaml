exp_name: './exp_output/DNA_Rendering_github/stage3_w_normal_w_nerf_guid_w_img_loss_w_view_attention_w_motion_attention'
width: 768 # 512
height: 768 # 512

NeRF:
  pretrain_nerf: False
  use_smpl_dist_mask: True
  nerf_cond_type: '480_480_upscale'
  depth_resolution: 48

test_nerf: False

data:
  video_folder: '/group2/3d/shoukanghu/champ_process_lw/data/DNA_Rendering/test'
  # ref_image_path: 'example_data/ref_images/ref-09.png'  # reference image path
  # guidance_data_folder: 'example_data/motions/motion-09'  # corresponding motion sequence folder
  frame_range: [0, 144] # [Optional] specify a frame range: [min_frame_idx, max_frame_idx] to select a clip from a motion sequence  
  image_ratio: 0.375
  nerf_rs_scale: 0.625
seed: 42

base_model_path: 'pretrained_models/stable-diffusion-v1-5'
vae_model_path: 'pretrained_models/sd-vae-ft-mse'
image_encoder_path: 'pretrained_models/image_encoder'

# ckpt_dir: 'pretrained_models/champ'
# motion_module_path: 'pretrained_models/champ/motion_module.pth'
ckpt_dir: 'exp_output/DNA_Rendering_github/stage1_w_normal_w_nerf_guid_w_img_loss/saved_models/'
view_module_path: 'exp_output/DNA_Rendering_github/stage2_w_normal_w_nerf_guid_w_img_loss_w_view_attention/saved_models/view_module-20000.pth'
motion_module_path: 'exp_output/DNA_Rendering_github/stage3_w_normal_w_nerf_guid_w_img_loss_w_view_attention_w_motion_attention/saved_models/motion_module-20000.pth'

num_inference_steps: 20
guidance_scale: 3.5
enable_zero_snr: true
weight_dtype: "fp16"

guidance_types:
  # - 'depth'
  - 'normal'
  # - 'semantic_map'
  # - 'dwpose'
  - 'nerf'

noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "linear"
  steps_offset:        1
  clip_sample:         false

unet_additional_kwargs:
  use_inflated_groupnorm: true
  unet_use_cross_frame_attention: false 
  unet_use_temporal_attention: false
  # crossview module
  use_crossview_3d_attention: false
  use_crossview_module: true
  crossview_module_resolutions:
  # - 1
  - 2
  - 4
  - 8
  crossview_module_mid_block: true 
  crossview_module_decoder_only: false
  crossview_module_type: Vanilla
  crossview_module_kwargs:
    num_attention_heads: 8
    num_transformer_block: 1
    attention_block_types:
    - Crossview_Self
    - Crossview_Self
    crossview_position_encoding: false
    crossview_position_encoding_max_len: 32
    crossview_attention_dim_div: 1
  # motion module
  use_motion_module: true
  motion_module_resolutions:
  # - 1
  - 2
  - 4
  - 8
  motion_module_mid_block: true 
  motion_module_decoder_only: false
  motion_module_type: Vanilla
  motion_module_kwargs:
    num_attention_heads: 8
    num_transformer_block: 1
    attention_block_types:
    - Temporal_Self
    - Temporal_Self
    temporal_position_encoding: true
    temporal_position_encoding_max_len: 32
    temporal_attention_dim_div: 1

guidance_encoder_kwargs:
  guidance_embedding_channels: 320
  guidance_input_channels: 3
  block_out_channels: [16, 32, 96, 256]

enable_xformers_memory_efficient_attention: true
